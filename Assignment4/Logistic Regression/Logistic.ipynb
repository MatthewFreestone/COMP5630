{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from data_process import get_CIFAR10_data, get_MUSHROOM_data\n",
    "from scipy.spatial import distance\n",
    "from models import Perceptron, SVM, Softmax, Logistic\n",
    "from kaggle_submission import output_submission_csv\n",
    "%matplotlib inline\n",
    "\n",
    "# For auto-reloading external modules\n",
    "# See http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Mushroom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells we determine the splitting of the mushroom dataset.\n",
    "<br /> TRAINING + VALIDATION = 0.8, TESTING = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING = 0.6 indicates 60% of the data is used as the training dataset.\n",
    "VALIDATION = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples:  4874\n",
      "Number of val samples:  1625\n",
      "Number of test samples:  1625\n"
     ]
    }
   ],
   "source": [
    "data = get_MUSHROOM_data(VALIDATION)\n",
    "X_train_MR, y_train_MR = data['X_train'], data['y_train']\n",
    "X_val_MR, y_val_MR = data['X_val'], data['y_val']\n",
    "X_test_MR, y_test_MR = data['X_test'], data['y_test']\n",
    "n_class_MR = len(np.unique(y_test_MR))\n",
    "\n",
    "print(\"Number of train samples: \", X_train_MR.shape[0])\n",
    "print(\"Number of val samples: \", X_val_MR.shape[0])\n",
    "print(\"Number of test samples: \", X_test_MR.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes how well your model performs using accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(pred, y_test):\n",
    "    return np.sum(y_test == pred) / len(y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Classifier has 2 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - controls how much we change the current weights of the classifier during each update. We set it at a default value of 0.5, but you should experiment with different values. We recommend changing the learning rate by factors of 10 and observing how the performance of the classifier changes. You should also try adding a **decay** which slowly reduces the learning rate over each epoch.\n",
    "- **Number of Epochs** - An epoch is a complete iterative pass over all of the data in the dataset. During an epoch we predict a label using the classifier and then update the weights of the classifier according to the logistic regression update rule for each sample in the training set. You should try different values for the number of training epochs and report your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the Logistic Classifier in the **models/logistic.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the Logistic classifier class \n",
    "- The train function of the Logistic class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Logistic Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m lr \u001b[38;5;241m=\u001b[39m Logistic(learning_rate, n_epochs)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_MR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_MR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m lr\u001b[38;5;241m.\u001b[39mw\n",
      "File \u001b[1;32mc:\\Users\\Matthew\\Desktop\\Homework\\COMP5630\\Assignment4\\Logistic Regression\\models\\logistic.py:43\u001b[0m, in \u001b[0;36mLogistic.train\u001b[1;34m(self, X_train, y_train)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39m# For this assignment, the bias w_0 will be at the end of the weight vector\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39;49mappend([\u001b[39m1\u001b[39;49m]\u001b[39m*\u001b[39;49mN, X_train, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m))\n\u001b[0;32m     44\u001b[0m P1_given_X \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m X: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mdot(X,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw[\u001b[39m1\u001b[39m:]))\n\u001b[0;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs):\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Matthew\\Desktop\\Homework\\COMP5630\\venv\\lib\\site-packages\\numpy\\lib\\function_base.py:5444\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     values \u001b[39m=\u001b[39m ravel(values)\n\u001b[0;32m   5443\u001b[0m     axis \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mndim\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m-> 5444\u001b[0m \u001b[39mreturn\u001b[39;00m concatenate((arr, values), axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.5\n",
    "# n_epochs = 10\n",
    "learning_rate = 0.001\n",
    "n_epochs = 1\n",
    "\n",
    "lr = Logistic(learning_rate, n_epochs)\n",
    "lr.train(X_train_MR, y_train_MR)\n",
    "lr.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 81.575708\n"
     ]
    }
   ],
   "source": [
    "pred_lr = lr.predict(X_train_MR)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_lr, y_train_MR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 8, ..., 3, 4, 0],\n",
       "       [5, 0, 4, ..., 2, 3, 1],\n",
       "       [5, 2, 8, ..., 3, 3, 3],\n",
       "       ...,\n",
       "       [3, 3, 4, ..., 7, 4, 4],\n",
       "       [2, 0, 3, ..., 1, 5, 4],\n",
       "       [5, 3, 2, ..., 7, 1, 6]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_MR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Logistic Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = lr.predict(X_val_MR)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_lr, y_val_MR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = lr.predict(X_test_MR)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_lr, y_test_MR)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "c3aa00aded8185b1b121d9a816507de5a835b81eeb963c94a602efd8ecf34dce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
