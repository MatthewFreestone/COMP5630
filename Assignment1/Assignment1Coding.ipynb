{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTES = [\n",
    "    \"AAGE\",\n",
    "    \"ACLSWKR\",\n",
    "    \"ADTIND\",\n",
    "    \"ADTOCC\",\n",
    "    # \"AGI\",\n",
    "    \"AHGA\",\n",
    "    \"AHRSPAY\",\n",
    "    \"AHSCOL\",\n",
    "    \"AMARITL\",\n",
    "    \"AMJIND\",\n",
    "    \"AMJOCC\",\n",
    "    \"ARACE\",\n",
    "    \"AREORGN\",\n",
    "    \"ASEX\",\n",
    "    \"AUNMEM\",\n",
    "    \"AUNTYPE\",\n",
    "    \"AWKSTAT\",\n",
    "    \"CAPGAIN\",\n",
    "    \"CAPLOSS\",\n",
    "    \"DIVVAL\",\n",
    "    # \"FEDTAX\",\n",
    "    \"FILESTAT\",\n",
    "    \"GRINREG\",\n",
    "    \"GRINST\",\n",
    "    \"HHDFMX\",\n",
    "    \"HHDREL\",\n",
    "    # \"MARSUPWT\",\n",
    "    \"MIGMTR1\",\n",
    "    \"MIGMTR3\",\n",
    "    \"MIGMTR4\",\n",
    "    \"MIGSAME\",\n",
    "    \"MIGSUN\",\n",
    "    \"NOEMP\",\n",
    "    \"PARENT\",\n",
    "    # \"PEARNVAL\",\n",
    "    \"PEFNTVTY\",\n",
    "    \"PEMNTVTY\",\n",
    "    \"PENATVTY\",\n",
    "    \"PRCITSHP\",\n",
    "    # \"PTOTVAL\",\n",
    "    \"SEOTR\",\n",
    "    # \"TAXINC\",\n",
    "    \"VETQVA\",\n",
    "    \"VETYN\",\n",
    "    \"WKSWORK\",\n",
    "    \"YEAR\",\n",
    "    \"RESULT\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('census-income.data', 'r') as f:\n",
    "    DATA = f.read().splitlines()\n",
    "    DATA = [x.split(', ') for x in DATA]\n",
    "    # drop the weight column\n",
    "    DATA = [x[:24]+x[25:] for x in DATA]\n",
    "# From names file\n",
    "NUM_ATTRIBUTES = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAGE: 73\t\tACLSWKR: Not in universe\t\tADTIND: 0\t\tADTOCC: 0\t\tAHGA: High school graduate\t\tAHRSPAY: 0\t\tAHSCOL: Not in universe\t\tAMARITL: Widowed\t\tAMJIND: Not in universe or children\t\tAMJOCC: Not in universe\t\tARACE: White\t\tAREORGN: All other\t\tASEX: Female\t\tAUNMEM: Not in universe\t\tAUNTYPE: Not in universe\t\tAWKSTAT: Not in labor force\t\tCAPGAIN: 0\t\tCAPLOSS: 0\t\tDIVVAL: 0\t\tFILESTAT: Nonfiler\t\tGRINREG: Not in universe\t\tGRINST: Not in universe\t\tHHDFMX: Other Rel 18+ ever marr not in subfamily\t\tHHDREL: Other relative of householder\t\tMIGMTR1: ?\t\tMIGMTR3: ?\t\tMIGMTR4: ?\t\tMIGSAME: Not in universe under 1 year old\t\tMIGSUN: ?\t\tNOEMP: 0\t\tPARENT: Not in universe\t\tPEFNTVTY: United-States\t\tPEMNTVTY: United-States\t\tPENATVTY: United-States\t\tPRCITSHP: Native- Born in the United States\t\tSEOTR: 0\t\tVETQVA: Not in universe\t\tVETYN: 2\t\tWKSWORK: 0\t\tYEAR: 95\t\tRESULT: - 50000.\n"
     ]
    }
   ],
   "source": [
    "zipped = list(zip(DATA[0],ATTRIBUTES))\n",
    "print('\\t\\t'.join(f\"{l[1]}: {l[0]}\" for l in zipped))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(dataset:list[list], atr:int) -> dict[list[list]]:\n",
    "    all_lists = dict()\n",
    "    for point in dataset:\n",
    "        val = point[atr]\n",
    "        if val not in all_lists:\n",
    "            all_lists[val] = [point]\n",
    "        else:\n",
    "            all_lists[val].append(point)\n",
    "    return all_lists\n",
    "\n",
    "def H_num(pos:int, neg:int):\n",
    "    if (pos == 0 or neg == 0):\n",
    "        return 0\n",
    "    return -1*(pos/(pos+neg))*math.log((pos/(pos+neg)),2) - (neg/(pos+neg)) * math.log((neg/(pos+neg)),2)\n",
    "\n",
    "def result_partition(dataset:list[list]):\n",
    "    pos_list = []\n",
    "    neg_list = []\n",
    "    for point in dataset:\n",
    "        if point[40] == '- 50000.':\n",
    "            neg_list.append(point)\n",
    "        else:\n",
    "            pos_list.append(point)\n",
    "    return (pos_list, neg_list)\n",
    "\n",
    "def H(inlist:list):\n",
    "    pos_list, neg_list = result_partition(inlist)\n",
    "    pos, neg = len(pos_list), len(neg_list)\n",
    "    return H_num(pos,neg)\n",
    "\n",
    "def H_many(lists: list[list]):\n",
    "    total_len = sum(len(l) for l in lists)\n",
    "    total = 0\n",
    "    for l in lists:\n",
    "        total += H(l) * (len(l) / total_len)\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole dataset: E = 0.3356\n",
      "[('HHDREL', 0.14624299588736347), ('ADTOCC', 0.24301600254861988), ('AHGA', 0.2546131441375053), ('AMJOCC', 0.2585425745589341), ('VETYN', 0.2779912663787357)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Whole dataset: E = {H(DATA):.4f}\")\n",
    "results = [(ATTRIBUTES[i],H_many(partition(DATA, i).values())) for i in range(NUM_ATTRIBUTES)]\n",
    "results.sort(key=lambda x: x[1])\n",
    "print(results[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find single best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best pick: ADTOCC with gain 0.0925\n"
     ]
    }
   ],
   "source": [
    "start_e = H(DATA)\n",
    "best_pick = -1\n",
    "best_gain = 0\n",
    "for i in range(NUM_ATTRIBUTES):\n",
    "    gain = start_e - H_many(partition(DATA, i).values())\n",
    "    # print(f\"{ATTRIBUTES[i]}: E = {gain:.4f}\")\n",
    "    if gain > best_gain:\n",
    "        best_gain = gain\n",
    "        best_pick = i\n",
    "print(f\"Best pick: {ATTRIBUTES[best_pick]} with gain {best_gain:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.tree=dict()\n",
    "    def predict(self, tree, point):\n",
    "        '''Tree is dict or string'''\n",
    "        if type(tree) != dict:\n",
    "            return tree\n",
    "        else:\n",
    "            attr = list(tree.keys())[0]\n",
    "            val = point[attr]\n",
    "            return self.predict(tree[attr][val], point)\n",
    "    def training_error(self):\n",
    "        correct_count = 0\n",
    "        wrong_count = 0\n",
    "        for point in DATA:\n",
    "            if self.predict(self.tree, point) == point[40]:\n",
    "                correct_count += 1\n",
    "            else:\n",
    "                wrong_count += 1\n",
    "        return (correct_count / (correct_count + wrong_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_best_atr(dataset:list[list]):\n",
    "    '''Returns best pick, attributes'''\n",
    "    start_e = H(dataset)\n",
    "    best_pick = -1\n",
    "    best_pick_attributes = []\n",
    "    best_gain = 0\n",
    "    for i in range(NUM_ATTRIBUTES):\n",
    "        partitioned_data = partition(dataset, i)\n",
    "        gain = start_e - H_many(partitioned_data.values())\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_pick = i\n",
    "            best_pick_attributes = partitioned_data.keys()\n",
    "    return best_pick, best_pick_attributes\n",
    "\n",
    "def get_data_partition(dataset:list[list], atr:int, value):\n",
    "    return partition(dataset, atr)[value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_train(dataset:list[list], tree:dict, max_depth:int, depth:int=1):\n",
    "    if depth > max_depth:\n",
    "        return \n",
    "        \n",
    "    next_pick, atr_values = get_next_best_atr(dataset)\n",
    "    if next_pick == -1:\n",
    "        return\n",
    "\n",
    "    tree[next_pick]=dict()\n",
    "    for atr_val in atr_values:\n",
    "        partitioned_data = get_data_partition(dataset, next_pick, atr_val)\n",
    "        # If we have a perfect class, make a leaf node\n",
    "        if (H(partitioned_data) == 0):\n",
    "            tree[next_pick][atr_val] = partitioned_data[0][40]\n",
    "        elif (depth+1) > max_depth:\n",
    "            # We are not allowed to go deeper, so make a guess at what anything here is instead of making a dict\n",
    "            pos_list, neg_list = result_partition(partitioned_data)\n",
    "            tree[next_pick][atr_val] = '+ 50000.' if len(pos_list) > len(neg_list) else '- 50000.'\n",
    "        else:\n",
    "            tree[next_pick][atr_val] = dict()\n",
    "            rec_train(partitioned_data, tree[next_pick][atr_val], max_depth, depth+1)\n",
    "            # If we have a -1, make a leaf node\n",
    "            if len(tree[next_pick][atr_val]) == 0:\n",
    "                pos_list, neg_list = result_partition(partitioned_data)\n",
    "                tree[next_pick][atr_val] = '+ 50000.' if len(pos_list) > len(neg_list) else '- 50000.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DEPTH = 2\n",
    "curr_data = DATA[:]\n",
    "\n",
    "model = Model()\n",
    "rec_train(curr_data, model.tree, MAX_DEPTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For depth 2, error was 0.06256421565433556\n"
     ]
    }
   ],
   "source": [
    "MAX_DEPTH = 2\n",
    "curr_data = DATA[:]\n",
    "\n",
    "model = Model()\n",
    "rec_train(curr_data, model.tree, MAX_DEPTH)\n",
    "\n",
    "print(f\"For depth {MAX_DEPTH}, error was {1 - model.training_error()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For depth 3, error was 0.041113054635305235\n"
     ]
    }
   ],
   "source": [
    "MAX_DEPTH = 3\n",
    "curr_data = DATA[:]\n",
    "\n",
    "model = Model()\n",
    "rec_train(curr_data, model.tree, MAX_DEPTH)\n",
    "\n",
    "print(f\"For depth {MAX_DEPTH}, error was {1 - model.training_error()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For depth 4, error was 0.02552587922194438\n"
     ]
    }
   ],
   "source": [
    "MAX_DEPTH = 4\n",
    "curr_data = DATA[:]\n",
    "\n",
    "model = Model()\n",
    "rec_train(curr_data, model.tree, MAX_DEPTH)\n",
    "\n",
    "print(f\"For depth {MAX_DEPTH}, error was {1 - model.training_error()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For depth 5, error was 0.015933000205490044\n"
     ]
    }
   ],
   "source": [
    "MAX_DEPTH = 5\n",
    "curr_data = DATA[:]\n",
    "\n",
    "model = Model()\n",
    "rec_train(curr_data, model.tree, MAX_DEPTH)\n",
    "\n",
    "print(f\"For depth {MAX_DEPTH}, error was {1 - model.training_error()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole dataset: E = 1.0000\n",
      "[('AAGE', 1.0), ('ACLSWKR', 1.0), ('ADTIND', 1.0), ('ADTOCC', 1.0), ('AHGA', 1.0)]\n",
      "['32', 'Private', '25', '35', 'Bachelors degree(BA AB BS)', '0', 'Not in universe', 'Married-civilian spouse present', 'Manufacturing-nondurable goods', 'Precision production craft & repair', 'White', 'All other', 'Male', 'Not in universe', 'Not in universe', 'Children or Armed Forces', '0', '0', '0', 'Joint both under 65', 'Not in universe', 'Not in universe', 'Householder', 'Householder', 'Nonmover', 'Nonmover', 'Nonmover', 'Yes', 'Not in universe', '6', 'Not in universe', 'United-States', 'United-States', 'United-States', 'Native- Born in the United States', '0', 'Not in universe', '2', '52', '94', '50000+.']\n",
      "['32', 'Private', '25', '35', 'Bachelors degree(BA AB BS)', '0', 'Not in universe', 'Married-civilian spouse present', 'Manufacturing-nondurable goods', 'Precision production craft & repair', 'White', 'All other', 'Male', 'Not in universe', 'Not in universe', 'Children or Armed Forces', '0', '0', '0', 'Joint both under 65', 'Not in universe', 'Not in universe', 'Householder', 'Householder', 'Nonmover', 'Nonmover', 'Nonmover', 'Yes', 'Not in universe', '6', 'Not in universe', 'United-States', 'United-States', 'United-States', 'Native- Born in the United States', '0', 'Not in universe', '2', '52', '94', '- 50000.']\n"
     ]
    }
   ],
   "source": [
    "# Conflict Example\n",
    "partitioned_data = get_data_partition(DATA, 3, '35')\n",
    "partitioned_data = get_data_partition(partitioned_data, 18, '0')\n",
    "partitioned_data = get_data_partition(partitioned_data, 2, '25')\n",
    "partitioned_data = get_data_partition(partitioned_data, 0, '32')\n",
    "\n",
    "print(f\"Whole dataset: E = {H(partitioned_data):.4f}\")\n",
    "results = [(ATTRIBUTES[i],H_many(partition(partitioned_data, i).values())) for i in range(NUM_ATTRIBUTES)]\n",
    "results.sort(key=lambda x: x[1])\n",
    "\n",
    "print(results[:5])\n",
    "print(partitioned_data[0])\n",
    "print(partitioned_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For depth 6, error was 0.007718408404043697\n"
     ]
    }
   ],
   "source": [
    "MAX_DEPTH = 6\n",
    "curr_data = DATA[:]\n",
    "\n",
    "model = Model()\n",
    "rec_train(curr_data, model.tree, MAX_DEPTH)\n",
    "\n",
    "print(f\"For depth {MAX_DEPTH}, error was {1 - model.training_error()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For depth 7, error was 0.0027064548949243816\n"
     ]
    }
   ],
   "source": [
    "MAX_DEPTH = 7\n",
    "curr_data = DATA[:]\n",
    "\n",
    "model = Model()\n",
    "rec_train(curr_data, model.tree, MAX_DEPTH)\n",
    "\n",
    "print(f\"For depth {MAX_DEPTH}, error was {1 - model.training_error()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For depth 8, error was 0.0012730361913162458\n"
     ]
    }
   ],
   "source": [
    "MAX_DEPTH = 8\n",
    "curr_data = DATA[:]\n",
    "\n",
    "model = Model()\n",
    "rec_train(curr_data, model.tree, MAX_DEPTH)\n",
    "\n",
    "print(f\"For depth {MAX_DEPTH}, error was {1 - model.training_error()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For depth 9, error was 0.0008019125614591172\n"
     ]
    }
   ],
   "source": [
    "MAX_DEPTH = 9\n",
    "curr_data = DATA[:]\n",
    "\n",
    "model = Model()\n",
    "rec_train(curr_data, model.tree, MAX_DEPTH)\n",
    "\n",
    "print(f\"For depth {MAX_DEPTH}, error was {1 - model.training_error()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For depth 10, error was 0.0005563268395122334\n"
     ]
    }
   ],
   "source": [
    "MAX_DEPTH = 10\n",
    "curr_data = DATA[:]\n",
    "\n",
    "model = Model()\n",
    "rec_train(curr_data, model.tree, MAX_DEPTH)\n",
    "\n",
    "print(f\"For depth {MAX_DEPTH}, error was {1 - model.training_error()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
